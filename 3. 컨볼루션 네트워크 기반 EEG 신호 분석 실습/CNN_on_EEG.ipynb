{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_on_EEG.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vmN4DljuGyCj","colab_type":"text"},"cell_type":"markdown","source":["## 컨볼루션 네트워크 기반 EEG신호 분석\n"]},{"metadata":{"id":"X_uFnbGgHKGe","colab_type":"text"},"cell_type":"markdown","source":["## **Dataset**\n","\n","### **Motor Imagery EEG** \n","BCI Competition IV-IIa dataset \\\\\n","http://www.bbci.de/competition/iv/#dataset2a/ \\\\\n","4 class motor imagery (Left hand, Right hand, Feet, and Tongue) \\\\\n","9 subjects, 72 trials per each class, 2 sessions for each subject\\\\\n","22 Ag/AgCl electrode channels, 0.5~50Hz band-pass filtering\\\\\n","250Hz sampling\n","\n","##** Preprocessing**\n","실험의 편의를 위해 1번 subject의 Left hand, Right hand의 두 가지 class만 가져와서 사용\\\\\n","Fixation cross, resting state signal의 평균값을, motor imagery의 cue에서 빼줌\n"]},{"metadata":{"id":"opulWz2LIK6H","colab_type":"text"},"cell_type":"markdown","source":["## **Library Download**"]},{"metadata":{"id":"NLsFyfjQMPmU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"69256da5-19db-4a54-e849-7199ccc2eb29","executionInfo":{"status":"ok","timestamp":1532970217977,"user_tz":-540,"elapsed":3856,"user":{"displayName":"WONJUN KO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114323399769062048290"}}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from sklearn.metrics import accruacy_score # To estimate accruacy\n","!pip install mne # To plot topography\n","from mne.viz import plot_topomap\n","from mne.channels import read_montage\n","from mne import EvokedArray, create_info\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.16.2)\r\n"],"name":"stdout"}]},{"metadata":{"id":"lG_Rd8XEIm0r","colab_type":"code","colab":{}},"cell_type":"code","source":["# Dataset download\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/A01T.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/A01E.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/A01E_label.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/w.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/conv_input_class1.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/conv_output_class1.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/conv_input_class2.npy\n","!wget -nc -q https://github.com/ku-milab/Neuroimage-Analysis-Tutorial/raw/master/data/conv_output_class2.npy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZdncoVjrtzqQ","colab_type":"code","colab":{}},"cell_type":"code","source":["## Define moduels\n","def load_data(train):\n","    if train == True:\n","        data = np.load(\"./A01T.npy\") # (22, 750, 144)\n","        label = np.zeros(shape=(72))\n","        label = np.concatenate((label, label+1), 0) # (144,)\n","        return data, label\n","    else:\n","        data = np.load(\"./A01E.npy\") # (22, 750, 144)\n","        label = np.load(\"./A01E_label.npy\") # (144,)\n","        return data, label\n","\n","def get_params(name, shape, n_filter):\n","    w = tf.get_variable(name=name + \"w\", shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n","                        dtype=tf.float32)\n","    b = tf.Variable(name=name + \"b\", initial_value=tf.constant(0.1, shape=[n_filter], dtype=tf.float32))\n","    return w, b\n","\n","def conv(input, w, b):\n","    conv = tf.nn.conv2d(input=input, filter=w, strides=(1, 1, 1, 1), padding=\"VALID\")\n","    return tf.nn.bias_add(conv, b)\n","\n","def max_pool(input):\n","    return tf.nn.max_pool(value=input, ksize=(1, 1, 3, 1), strides=(1, 1, 3, 1), padding=\"VALID\")\n","\n","def lin_map(input, name, num_output):\n","    num_input = input.get_shape().as_list()[-1]\n","    w, b = get_params(name=name, shape=(num_input, num_output), n_filter=num_output)\n","    logit = tf.nn.bias_add(tf.matmul(input, w), b)\n","    return logit, tf.nn.sigmoid(logit)\n","\n","def batchnorm(input):\n","    return tf.nn.batch_normalization(x=input, mean=0, variance=1, offset=None, scale=None, variance_epsilon=1e-8)\n","\n","def dropout(input, keep_prob):\n","    return tf.nn.dropout(x=input, keep_prob=keep_prob)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JqE9-dreKK3G","colab_type":"text"},"cell_type":"markdown","source":["## **Deep ConvNet**"]},{"metadata":{"id":"Tiw6xvLjF9vA","colab_type":"code","colab":{}},"cell_type":"code","source":["## Assemble Deep ConvNet (Schirrmeister et al., HBM, 2017)\n","def deepconv(input, keep=0.5, reuse=None):\n","    with tf.variable_scope(\"deepconv\") as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","            keep = 1.0\n","\n","        # 1st Temporal Convolution, Linear activation\n","        w1, b1 = get_params(name=\"conv1\", shape=(1, 10, 1, 25), n_filter=25)\n","        conv1 = conv(input=input, w=w1, b=b1) # (32, 22, 503, 25)\n","\n","        # 2nd Spatial Convolution, ELU activation, Max pooling\n","        w2, b2 = get_params(name=\"conv2\", shape=(22, 1, 25, 25), n_filter=25)\n","        conv2 = conv(input=conv1, w=w2, b=b2)\n","        conv2_ap = conv2\n","        conv2 = batchnorm(conv2)\n","        conv2 = tf.nn.elu(conv2)\n","        conv2 = max_pool(conv2)\n","        conv2 = dropout(conv2, keep) # (32, 1, 167, 25)\n","\n","        # 3rd Temporal Convolution, ELU activation, Max pooling\n","        w3, b3 = get_params(name=\"conv3\", shape=(1, 10, 25, 50), n_filter=50)\n","        conv3 = conv(input=conv2, w=w3, b=b3)\n","        conv3 = batchnorm(conv3)\n","        conv3 = tf.nn.elu(conv3)\n","        conv3 = max_pool(conv3)\n","        conv3 = dropout(conv3, keep) # (32, 1, 52, 50)\n","\n","        # 4th Temporal Convolution, ELU activation\n","        w4, b4 = get_params(name=\"deep4\", shape=(1, 10, 50, 100), n_filter=100)\n","        conv4 = conv(input=conv3, w=w4, b=b4)\n","        conv4 = batchnorm(conv4)\n","        conv4 = tf.nn.elu(conv4)\n","        conv4 = max_pool(conv4)\n","        conv4 = dropout(conv4, keep) # (32, 1, 14, 100)\n","\n","        # 5th Temporal Convolution, ELU activation\n","        w5, b5 = get_params(name=\"deep5\", shape=(1, 10, 100, 200), n_filter=200)\n","        conv5 = conv(input=conv4, w=w5, b=b5)\n","        conv5 = batchnorm(conv5)\n","        conv5 = tf.nn.elu(conv5)\n","        conv5 = max_pool(conv5)\n","        conv5 = dropout(conv5, keep) # (32, 1, 1, 200)\n","\n","        # Linear Mapping\n","        batch = conv5.get_shape().as_list()[0]\n","        conv5 = tf.reshape(conv5, shape=(batch, -1)) # (32, 200)\n","        logit, output = lin_map(input=conv5, name=\"output\", num_output=2) # (32, 2), (32, 2)\n","    return logit, output, w2, conv1, conv2_ap"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WYNpgUVXt1rX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"a78e3364-034e-403d-9fd3-cccd80cefd58","executionInfo":{"status":"ok","timestamp":1532970220868,"user_tz":-540,"elapsed":962,"user":{"displayName":"WONJUN KO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114323399769062048290"}}},"cell_type":"code","source":["## Experiment\n","# Load dataset\n","train_data, train_label = load_data(train=True) # (22, 750, 144), (144,)\n","print(\"Train data shape:\", train_data.shape)\n","print(\"Train label shape:\", train_label.shape)\n","test_data, test_label = load_data(train=False) # (22, 750, 144), (144,)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Train data shape: (2, 22, 700, 72)\n","Train label shape: (2, 72)\n"],"name":"stdout"}]},{"metadata":{"id":"oPoEHhsat1yd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define hyperparameters\n","batch_size = 32\n","num_channel = 22\n","window_size = 512\n","rest_point = train_data.shape[-2] - window_size + 1 # 239\n","num_class = 2\n","num_trials = train_data.shape[-1] # 144\n","num_timepoints = train_data.shape[1] # 750\n","total_epoch = 4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_O7_VLm0OJIb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Placeholding\n","X = tf.placeholder(dtype=tf.float32, shape=(batch_size, num_channel, window_size, 1))\n","Y = tf.placeholder(dtype=tf.float32, shape=(batch_size))\n","X_test = tf.placeholder(dtype=tf.float32, shape=(rest_point , num_channel, window_size, 1)) # For test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r48wMHdjMkvH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Calculate loss\n","label = tf.one_hot(tf.cast(Y, tf.int64), depth=2) # One-hot encoding\n","loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logit))\n","\n","# Call parameters\n","parameters = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"deepconv\")\n","\n","# Build an Adam-optimizer\n","optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, var_list=parameters)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WOX5fiaCGdxy","colab_type":"code","colab":{}},"cell_type":"code","source":["## Open Tensorflow session\n","sess = tf.Session()\n","\n","# Initialize all variables\n","sess.run(tf.global_variables_initializer())\n","\n","# Call model saver\n","saver = tf.train.Saver(keep_checkpoint_every_n_hours=8, max_to_keep=100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EfdQ_ROKM32N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2877},"outputId":"28ae237e-3bc5-4e9c-fd8d-a20fd0eae53a","executionInfo":{"status":"ok","timestamp":1532970303557,"user_tz":-540,"elapsed":65898,"user":{"displayName":"WONJUN KO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114323399769062048290"}}},"cell_type":"code","source":["## Model training\n","print(\"Begin Training\")\n","total_batch = int((rest_point * num_trials) / batch_size)  # int(34416/32)\n","for epoch in range(total_epoch):\n","    # Randomize the training dataset\n","    rand_idx = np.random.permutation(rest_point * num_trials) # 34416\n","    for batch in range(total_batch):\n","        batch_x = np.empty(shape=(batch_size, num_channel, window_size, 1))\n","        batch_y = np.empty(shape=batch_size)\n","        for pos in range(batch_size):\n","            position = np.unravel_index(indices=rand_idx[batch * batch_size + pos], dims=(rest_point, num_trials))\n","            batch_x[pos, :, :, :] = np.expand_dims(train_data[:, position[0]:position[0]+window_size, position[1]], axis=-1)\n","            batch_y[pos] = train_label[position[1]]\n","\n","        # Feed dictionary\n","        _, loss_ = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y})\n","    print(\"%dth Epoch Training Loss: %f\" %(epoch + 1, loss_))\n","print(\"Model Saving\")\n","saver.save(sess, \"./model.ckpt\")\n","print(\"End Training\\n\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Begin Training\n","[0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 1.]\n","[[0.46312714]\n"," [0.3238025 ]\n"," [0.49918225]\n"," [0.75741595]\n"," [0.28158665]\n"," [0.7940784 ]\n"," [0.66617525]\n"," [0.5963476 ]\n"," [0.6430868 ]\n"," [0.7185918 ]\n"," [0.6454005 ]\n"," [0.29727548]\n"," [0.7970066 ]\n"," [0.3170322 ]\n"," [0.33914486]\n"," [0.39120576]\n"," [0.36655012]\n"," [0.85369337]\n"," [0.4804779 ]\n"," [0.7621475 ]\n"," [0.5107533 ]\n"," [0.52139986]\n"," [0.58759683]\n"," [0.46178007]\n"," [0.2084667 ]\n"," [0.6584383 ]\n"," [0.22862521]\n"," [0.5425312 ]\n"," [0.3098023 ]\n"," [0.6387328 ]\n"," [0.58469194]\n"," [0.46962637]]\n","1th Epoch Training Loss: 0.806807\n","[0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n"," 1. 0. 0. 1. 0. 0. 1. 1.]\n","[[0.31113926]\n"," [0.29082894]\n"," [0.62426704]\n"," [0.85455877]\n"," [0.28456503]\n"," [0.4120317 ]\n"," [0.62218577]\n"," [0.41007864]\n"," [0.7463413 ]\n"," [0.19125758]\n"," [0.18485707]\n"," [0.4394604 ]\n"," [0.4265429 ]\n"," [0.7143759 ]\n"," [0.33601648]\n"," [0.3487909 ]\n"," [0.73380786]\n"," [0.7172403 ]\n"," [0.5419623 ]\n"," [0.2253439 ]\n"," [0.5902801 ]\n"," [0.5938068 ]\n"," [0.45020473]\n"," [0.78760177]\n"," [0.6719593 ]\n"," [0.5747729 ]\n"," [0.33674502]\n"," [0.715342  ]\n"," [0.7325191 ]\n"," [0.6110623 ]\n"," [0.46294603]\n"," [0.36516193]]\n","2th Epoch Training Loss: 0.889494\n","[1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 1. 1. 0. 0. 1. 0. 0.]\n","[[0.76796263]\n"," [0.45474878]\n"," [0.42909113]\n"," [0.41590354]\n"," [0.35955137]\n"," [0.37076145]\n"," [0.34420022]\n"," [0.56703246]\n"," [0.5872935 ]\n"," [0.5226881 ]\n"," [0.35852313]\n"," [0.4608761 ]\n"," [0.4896154 ]\n"," [0.67172503]\n"," [0.43064535]\n"," [0.6611292 ]\n"," [0.40883106]\n"," [0.39002004]\n"," [0.5584877 ]\n"," [0.35910133]\n"," [0.6147243 ]\n"," [0.48993808]\n"," [0.5130807 ]\n"," [0.73569655]\n"," [0.38559923]\n"," [0.4852343 ]\n"," [0.65701854]\n"," [0.421734  ]\n"," [0.5830418 ]\n"," [0.44982827]\n"," [0.35041726]\n"," [0.74237883]]\n","3th Epoch Training Loss: 0.730713\n","[1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n"," 1. 1. 0. 0. 0. 0. 1. 0.]\n","[[0.5487592 ]\n"," [0.5199967 ]\n"," [0.43497306]\n"," [0.6980779 ]\n"," [0.7848683 ]\n"," [0.48135304]\n"," [0.45083833]\n"," [0.8276429 ]\n"," [0.58580697]\n"," [0.20405877]\n"," [0.55126333]\n"," [0.5804321 ]\n"," [0.76268864]\n"," [0.6979317 ]\n"," [0.57424957]\n"," [0.57810074]\n"," [0.6024614 ]\n"," [0.69327873]\n"," [0.5194053 ]\n"," [0.65352076]\n"," [0.6213734 ]\n"," [0.7390498 ]\n"," [0.49116656]\n"," [0.35919282]\n"," [0.6827728 ]\n"," [0.5810734 ]\n"," [0.35621426]\n"," [0.6135228 ]\n"," [0.56433403]\n"," [0.6719374 ]\n"," [0.5439753 ]\n"," [0.403535  ]]\n","4th Epoch Training Loss: 0.688285\n","[1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n"," 0. 0. 0. 0. 1. 0. 1. 1.]\n","[[0.35677397]\n"," [0.5340917 ]\n"," [0.4675307 ]\n"," [0.6020468 ]\n"," [0.54523754]\n"," [0.30674267]\n"," [0.32818133]\n"," [0.56030935]\n"," [0.42619878]\n"," [0.67173856]\n"," [0.433584  ]\n"," [0.44162163]\n"," [0.47394422]\n"," [0.6077352 ]\n"," [0.54061204]\n"," [0.50382006]\n"," [0.31796682]\n"," [0.51418597]\n"," [0.5844554 ]\n"," [0.3344742 ]\n"," [0.5047364 ]\n"," [0.43205148]\n"," [0.44213784]\n"," [0.5704669 ]\n"," [0.47539487]\n"," [0.24867478]\n"," [0.40067926]\n"," [0.37328684]\n"," [0.66604215]\n"," [0.50133413]\n"," [0.5112224 ]\n"," [0.36251372]]\n","5th Epoch Training Loss: 0.687534\n"],"name":"stdout"}]},{"metadata":{"id":"p2jZLkNvMrcu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"dec7e0b3-fc56-4724-e316-d6397f3c1879","executionInfo":{"status":"ok","timestamp":1532970036646,"user_tz":-540,"elapsed":2685,"user":{"displayName":"WONJUN KO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114323399769062048290"}}},"cell_type":"code","source":["# Model test\n","print(\"Begin Test\")\n","print(\"Model Restoring\")\n","saver.restore(sess, \"./model.ckpt\")\n","prediction = np.empty(shape=(num_trials))\n","for trial in range(num_trials):\n","    batch_x_test = np.empty(shape=(rest_point, num_channel, window_size, 1))\n","    for i in range(rest_point):\n","        batch_x_test[i, :, :, :] = np.expand_dims(test_data[:, i:i+window_size, trial], axis=-1)\n","    pred_ = sess.run([pred], feed_dict={X_test:batch_x_test})\n","    pred_ = np.argmax(np.bincount(np.squeeze(np.argmax(np.asarray(pred_), -1)), minlength=2))\n","    prediction[trial] = pred_\n","\n","print(\"Binary Class Test Accuracy: %4f\" % (accuracy_score(y_true=test_label, y_pred=prediction)))\n","print(\"End Test\\n\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2 class classification accuracy: 0.513889\n"],"name":"stdout"}]},{"metadata":{"id":"hHKwlm1-KwOZ","colab_type":"text"},"cell_type":"markdown","source":["## **Activation Pattern** (Haufe *et al*.,, *NeuroImage*, 2014)\n","\n","## $$A\\equiv\\Sigma_x W\\Sigma_{\\hat{s}}^{-1}$$"]},{"metadata":{"id":"wVpOJoO7ImLZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load learned spatial weight vectors, inputs, and outputs\n","w = np.load(\"./w.npy\")\n","class1_input = np.load(\"./conv_input_class1.npy\")\n","class1_output = np.load(\"./conv_output_class1.npy\")\n","class2_input = np.load(\"./conv_input_class2.npy\")\n","class2_output = np.load(\"./conv_output_class2.npy\")\n","\n","# To calculate activation pattern, reshaping matrices\n","w = np.reshape(w, newshape=(22, 1, -1))\n","class1_input = np.moveaxis(class1_input, 0, -1)\n","class1_output = np.moveaxis(class1_output, 0, -1)\n","class2_input = np.moveaxis(class2_input, 0, -1)\n","class2_output = np.moveaxis(class2_output, 0, -1)\n","\n","# Calculate mean of covariance of inputs and outputs\n","class1_input = np.mean(np.reshape(class1_input, (22, 14, -1)), -1)\n","class1_output = np.mean(np.reshape(class1_output, (1, 1, -1)), -1)\n","class2_input = np.mean(np.reshape(class2_input, (22, 14, -1)), -1)\n","class2_output = np.mean(np.reshape(class2_output, (1, 1, -1)), -1)\n","\n","class1_activation_pattern = np.empty(shape=w.shape)\n","class2_activation_pattern = np.empty(shape=w.shape)\n","for i in range(class1_activation_pattern.shape[-1]):\n","    class1_activation_pattern[:, :, i] = np.matmul(np.cov(class1_input), w[:, :, i]) * 1/np.squeeze(class1_output)\n","    class2_activation_pattern[:, :, i] = np.matmul(np.cov(class2_input), w[:, :, i]) * 1/np.squeeze(class2_output)\n","\n","np.save(\"./class1_ap.npy\", class1_activation_pattern)\n","np.save(\"./class2_ap.npy\", class2_activation_pattern)"],"execution_count":0,"outputs":[]}]}